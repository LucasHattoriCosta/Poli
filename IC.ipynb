{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celúla de importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f2543226daa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lucas\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# resolution to succeed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: disable=undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mpython\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# pylint: enable=undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import dataset  & Data aumengtation\n",
    "\n",
    "train_asl = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 5,\n",
    "                                   rotation_range = 10,\n",
    "                                   zoom_range = 0.1, \n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_asl = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#Aqui acessamos a pasta com as fotos e colocamos os parâmetros.\n",
    "\n",
    "\n",
    "training_set_asl = train_asl.flow_from_directory('.\\dataset\\por favor 2',\n",
    "                                                 target_size = (64, 64),         # Define o tamanho do input desejado\n",
    "                                                 batch_size = 32,                # Define a quantidade de fotos por interação\n",
    "                                                 color_mode = \"grayscale\",       # Transformando\n",
    "                                                 shuffle = True,                 # Ordem aleatória de leitura das fotos numa classe\n",
    "                                                 class_mode = 'categorical')\n",
    "                                                \n",
    "validation_set_asl = test_asl.flow_from_directory('.\\dataset\\por favor',\n",
    "                                                 target_size = (64, 64),         # Define o tamanho do input desejado\n",
    "                                                 batch_size = 32,                # Define a quantidade de fotos por interação\n",
    "                                                 color_mode = \"grayscale\",       # Transformando\n",
    "                                                 shuffle = True,                 # Ordem aleatória de leitura das fotos numa classe\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 classes = ['a','b','d','g','s'] )   #Label associado as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (5,5), input_shape=(64, 64, 1), activation = 'sigmoid'))\n",
    "classifier.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "classifier.add(Conv2D(32, (5,5), input_shape=(64, 64, 1), activation = 'sigmoid'))\n",
    "\n",
    "classifier.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "classifier.add(Conv2D(32, (5,5), input_shape=(64, 64, 1), activation= 'sigmoid'))\n",
    "\n",
    "classifier.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(128, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(training_set_asl,\n",
    "                         epochs = 10,\n",
    "                         steps_per_epoch = 5,\n",
    "                         validation_data = validation_set_asl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
